#!/usr/bin/env python3
"""
One-Time Notepad Randomness Quality Analyzer

This script analyzes the randomness quality of files generated by the notepad_generator.py script.
It performs several statistical tests to evaluate the quality of randomness in the file content.

Usage:
    python randomness_analyzer.py <file_path>
    
Example:
    python randomness_analyzer.py my_notepad.txt
"""

import argparse
import math
import os
import sys
from collections import Counter
from typing import List, Tuple


def read_file_sample(file_path: str, sample_size: int = 1000000) -> bytes:
    """
    Read a sample of bytes from a file.
    
    Args:
        file_path: Path to the file
        sample_size: Maximum number of bytes to read (default: 1MB)
        
    Returns:
        Bytes from the file
    """
    file_size = os.path.getsize(file_path)
    
    with open(file_path, 'rb') as f:
        if file_size <= sample_size:
            # Read entire file if it's small enough
            return f.read()
        else:
            # Read a sample from the beginning, middle, and end
            chunk_size = sample_size // 3
            data = b''
            
            # Read from beginning
            f.seek(0)
            data += f.read(chunk_size)
            
            # Read from middle
            f.seek(file_size // 2)
            data += f.read(chunk_size)
            
            # Read from end
            f.seek(file_size - chunk_size)
            data += f.read(chunk_size)
            
            return data


def frequency_test(data: bytes) -> Tuple[float, str]:
    """
    Perform frequency (monobit) test.
    
    Args:
        data: Byte data to test
        
    Returns:
        Tuple of (p-value, test result description)
    """
    # Convert bytes to bits
    bits = ''.join(format(byte, '08b') for byte in data)
    n = len(bits)
    
    if n == 0:
        return 0.0, "Insufficient data"
    
    # Count ones and zeros
    ones = bits.count('1')
    zeros = n - ones
    
    # Calculate test statistic
    s_n = abs(ones - zeros)
    s_obs = s_n / math.sqrt(n)
    p_value = math.erfc(s_obs / math.sqrt(2))
    
    result = "PASS" if p_value >= 0.01 else "FAIL"
    return p_value, f"Frequency Test: {result} (p-value: {p_value:.6f})"


def block_frequency_test(data: bytes, block_size: int = 10000) -> Tuple[float, str]:
    """
    Perform block frequency test.
    
    Args:
        data: Byte data to test
        block_size: Size of blocks to test (default: 10000 bits)
        
    Returns:
        Tuple of (p-value, test result description)
    """
    # Convert bytes to bits
    bits = ''.join(format(byte, '08b') for byte in data)
    n = len(bits)
    
    if n < block_size:
        return 0.0, "Insufficient data for block frequency test"
    
    # Calculate number of blocks
    num_blocks = n // block_size
    if num_blocks == 0:
        return 0.0, "Insufficient data for block frequency test"
    
    # Calculate proportions for each block
    proportions = []
    for i in range(num_blocks):
        block = bits[i * block_size:(i + 1) * block_size]
        ones = block.count('1')
        proportions.append(ones / block_size)
    
    # Calculate chi-square statistic
    chi_square = 0.0
    for prop in proportions:
        chi_square += (prop - 0.5) ** 2
    
    chi_square *= 4 * block_size
    p_value = math.erfc(math.sqrt(chi_square / 2))
    
    result = "PASS" if p_value >= 0.01 else "FAIL"
    return p_value, f"Block Frequency Test: {result} (p-value: {p_value:.6f})"


def runs_test(data: bytes) -> Tuple[float, str]:
    """
    Perform runs test.
    
    Args:
        data: Byte data to test
        
    Returns:
        Tuple of (p-value, test result description)
    """
    # Convert bytes to bits
    bits = ''.join(format(byte, '08b') for byte in data)
    n = len(bits)
    
    if n < 100:
        return 0.0, "Insufficient data for runs test"
    
    # Count ones and calculate proportion
    ones = bits.count('1')
    pi = ones / n
    
    # Check if frequency test would pass
    tau = 2 / math.sqrt(n)
    if abs(pi - 0.5) >= tau:
        return 0.0, "Runs Test: FAIL (frequency test would fail)"
    
    # Count runs
    runs = 1
    for i in range(1, n):
        if bits[i] != bits[i-1]:
            runs += 1
    
    # Calculate p-value
    numerator = abs(runs - 2 * n * pi * (1 - pi))
    denominator = 2 * math.sqrt(2 * n) * pi * (1 - pi)
    p_value = math.erfc(numerator / denominator)
    
    result = "PASS" if p_value >= 0.01 else "FAIL"
    return p_value, f"Runs Test: {result} (p-value: {p_value:.6f})"


def longest_run_of_ones_test(data: bytes) -> Tuple[float, str]:
    """
    Perform longest run of ones test.
    
    Args:
        data: Byte data to test
        
    Returns:
        Tuple of (p-value, test result description)
    """
    # Convert bytes to bits
    bits = ''.join(format(byte, '08b') for byte in data)
    n = len(bits)
    
    if n < 128:
        return 0.0, "Insufficient data for longest run test"
    
    # Determine block size based on n
    if n < 6272:
        block_size = 8
    elif n < 750000:
        block_size = 128
    else:
        block_size = 10000
    
    # Calculate number of blocks
    num_blocks = n // block_size
    if num_blocks == 0:
        return 0.0, "Insufficient data for longest run test"
    
    # Find longest run of ones in each block
    longest_runs = []
    for i in range(num_blocks):
        block = bits[i * block_size:(i + 1) * block_size]
        max_run = 0
        current_run = 0
        
        for bit in block:
            if bit == '1':
                current_run += 1
                max_run = max(max_run, current_run)
            else:
                current_run = 0
        
        longest_runs.append(max_run)
    
    # Theoretical probabilities (simplified)
    if block_size == 8:
        # For block_size = 8
        pi = [0.2148, 0.3672, 0.2305, 0.1875]
        thresholds = [1, 2, 3, 4]
    else:
        # Simplified for larger blocks
        avg_run = sum(longest_runs) / len(longest_runs)
        # This is a simplified approach - a full implementation would use more complex tables
        pi = [0.1, 0.2, 0.3, 0.4]
        thresholds = [int(avg_run * 0.5), int(avg_run * 0.8), int(avg_run * 1.2), int(avg_run * 1.5)]
    
    # Count frequencies
    frequencies = [0, 0, 0, 0, 0]  # <t1, t1, t2, t3, >t3
    for run in longest_runs:
        if run < thresholds[0]:
            frequencies[0] += 1
        elif run < thresholds[1]:
            frequencies[1] += 1
        elif run < thresholds[2]:
            frequencies[2] += 1
        elif run < thresholds[3]:
            frequencies[3] += 1
        else:
            frequencies[4] += 1
    
    # Calculate chi-square
    chi_square = 0.0
    for i in range(len(pi)):
        expected = num_blocks * pi[i]
        if expected > 0:
            chi_square += (frequencies[i] - expected) ** 2 / expected
    
    # Degrees of freedom
    df = len(pi) - 1
    # Approximate p-value (simplified)
    p_value = math.exp(-chi_square / 2) if chi_square < 100 else 0.0
    
    result = "PASS" if p_value >= 0.01 else "FAIL"
    return p_value, f"Longest Run Test: {result} (p-value: {p_value:.6f})"


def entropy_test(data: bytes) -> Tuple[float, str]:
    """
    Calculate entropy of the data.
    
    Args:
        data: Byte data to test
        
    Returns:
        Tuple of (entropy value, test result description)
    """
    if len(data) == 0:
        return 0.0, "Insufficient data for entropy test"
    
    # Count byte frequencies
    counter = Counter(data)
    data_length = len(data)
    
    # Calculate entropy
    entropy = 0.0
    for count in counter.values():
        probability = count / data_length
        entropy -= probability * math.log2(probability)
    
    # Maximum possible entropy for 8-bit bytes
    max_entropy = 8.0
    normalized_entropy = entropy / max_entropy
    
    # Simple pass/fail based on entropy value
    result = "PASS" if normalized_entropy > 0.95 else "FAIL"
    return normalized_entropy, f"Entropy Test: {result} (entropy: {entropy:.4f})"


def correlation_test(data: bytes) -> Tuple[float, str]:
    """
    Perform autocorrelation test.
    
    Args:
        data: Byte data to test
        
    Returns:
        Tuple of (correlation value, test result description)
    """
    if len(data) < 100:
        return 0.0, "Insufficient data for correlation test"
    
    # Convert to bits
    bits = ''.join(format(byte, '08b') for byte in data)
    n = len(bits)
    
    # Calculate autocorrelation with shift of 1
    shift = 1
    matches = 0
    total = n - shift
    
    for i in range(total):
        if bits[i] == bits[i + shift]:
            matches += 1
    
    # Calculate correlation coefficient
    correlation = (2 * matches - total) / total
    
    # Absolute value for pass/fail
    abs_correlation = abs(correlation)
    result = "PASS" if abs_correlation < 0.1 else "FAIL"
    
    return abs_correlation, f"Correlation Test: {result} (correlation: {correlation:.6f})"


def analyze_randomness(file_path: str) -> None:
    """
    Analyze the randomness quality of a file.
    
    Args:
        file_path: Path to the file to analyze
    """
    print(f"Analyzing randomness quality of: {file_path}")
    print("=" * 60)
    
    # Check if file exists
    if not os.path.exists(file_path):
        print(f"Error: File '{file_path}' not found.")
        sys.exit(1)
    
    # Get file size
    file_size = os.path.getsize(file_path)
    print(f"File size: {file_size:,} bytes ({format_size(file_size)})")
    
    # Read sample data
    print("Reading file sample for analysis...")
    data = read_file_sample(file_path)
    print(f"Sample size: {len(data):,} bytes")
    print()
    
    # Perform all tests
    tests = [
        ("Frequency Test", frequency_test),
        ("Block Frequency Test", block_frequency_test),
        ("Runs Test", runs_test),
        ("Longest Run Test", longest_run_of_ones_test),
        ("Entropy Test", entropy_test),
        ("Correlation Test", correlation_test),
    ]
    
    results = []
    passed_tests = 0
    
    print("Running randomness tests:")
    print("-" * 40)
    
    for test_name, test_func in tests:
        try:
            if test_name == "Block Frequency Test":
                value, description = test_func(data, 1000)  # Smaller block size for sample
            else:
                value, description = test_func(data)
            
            # Extract result (PASS/FAIL)
            if "PASS" in description:
                passed_tests += 1
                result = "PASS"
            else:
                result = "FAIL"
            
            results.append((test_name, value, description, result))
            print(f"{test_name:<25} {result}")
            
        except Exception as e:
            error_msg = f"ERROR: {str(e)}"
            results.append((test_name, 0.0, error_msg, "ERROR"))
            print(f"{test_name:<25} ERROR")
    
    print("-" * 40)
    
    # Calculate overall score
    total_tests = len(tests)
    score = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
    
    # Determine quality rating
    if score >= 90:
        quality = "EXCELLENT"
    elif score >= 70:
        quality = "GOOD"
    elif score >= 50:
        quality = "FAIR"
    else:
        quality = "POOR"
    
    print(f"\nOverall Results:")
    print(f"Passed tests: {passed_tests}/{total_tests}")
    print(f"Quality Score: {score:.1f}%")
    print(f"Randomness Quality: {quality}")
    
    # Print detailed results table
    print(f"\nDetailed Test Results:")
    print("=" * 80)
    print(f"{'Test Name':<25} {'Result':<10} {'Value':<15} {'Description'}")
    print("-" * 80)
    
    for test_name, value, description, result in results:
        # Extract value from description for display
        if "p-value:" in description:
            val_str = description.split("p-value:")[1].split(")")[0]
        elif "entropy:" in description:
            val_str = description.split("entropy:")[1].split(")")[0]
        elif "correlation:" in description:
            val_str = description.split("correlation:")[1].split(")")[0]
        else:
            val_str = f"{value:.6f}" if isinstance(value, float) else str(value)
        
        print(f"{test_name:<25} {result:<10} {val_str:<15} {description}")
    
    print("=" * 80)


def format_size(size_bytes: int) -> str:
    """
    Format size in bytes to human readable format.
    
    Args:
        size_bytes: Size in bytes
        
    Returns:
        Human readable size string
    """
    if size_bytes == 0:
        return "0B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and i < len(size_names) - 1:
        size /= 1024.0
        i += 1
    
    return f"{size:.2f} {size_names[i]}"


def main():
    """Main function to parse arguments and analyze file randomness."""
    parser = argparse.ArgumentParser(
        description="Analyze the randomness quality of one-time notepad files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        "file",
        help="Path to the notepad file to analyze"
    )
    
    # Parse arguments
    args = parser.parse_args()
    
    try:
        # Analyze the file randomness
        analyze_randomness(args.file)
        
    except Exception as e:
        print(f"Unexpected error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()